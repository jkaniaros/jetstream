services:
  kafka-broker:
    image: apache/kafka
    container_name: kafka-broker
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://kafka-broker:9092,CONTROLLER://kafka-broker:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-broker:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LOG_RETENTION_BYTES: 1000000000 # delete logs every 1 GB
    # volumes:
    #   - ./data/kafka-data:/var/lib/kafka/data
    ports:
      - 9092:9092

  spark-master:
    image: bitnami/spark:3.5.3
    ports:
      - "7077:7077"
      - "8080:8080"
    environment:
      SPARK_MODE: master
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_PORT: 7077

  spark-worker:
    image: bitnami/spark:3.5.3
    depends_on:
      - spark-master
      - kafka-broker
    ports:
      - "8081:8081"
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      KAFKA_BROKER: kafka-broker:9092

  spark-app:
    build:
      context: ./spark
      dockerfile: Dockerfile
    depends_on:
      - spark-master
      - spark-worker
      - kafka-broker
      - mariadb
    environment:
      SPARK_MASTER_URL: spark://spark-master:7077
      KAFKA_BROKER: kafka-broker:9092
    restart: always # should never stop working, even if it is finished

  mariadb:
    image: mariadb:11.7.1-ubi9-rc
    environment:
      MYSQL_ROOT_PASSWORD: jetstream
      MYSQL_DATABASE: jetstream
    ports:
      - "3306:3306"
    volumes:
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql
      # - mariadb-data:/var/lib/mysql  # Persistent Volume for MariaDB, activate to persist data

  generator:
    build:
      context: ./app
    depends_on:
      - kafka-broker
      - spark-master
      - spark-worker
    environment:
      KAFKA_BROKER: kafka-broker:9092
    restart: on-failure

  # python-consumer:
  #   build:
  #     context: ./consumer
  #   depends_on:
  #     - kafka-broker
  #   environment:
  #     KAFKA_BROKER: kafka-broker:9092
  #   restart: on-failure